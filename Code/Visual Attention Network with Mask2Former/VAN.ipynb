{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f5ec7b6",
   "metadata": {},
   "source": [
    "In this notebook I will implement Mask2Former using Visual Attention Network(VAN) backbone. Mask2Former consists of 3 elements, a backbone feature extractor, a pixel decoder and a transformer decoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90fbd7d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Firstly I created a virtual environment for this project, using the command  \n",
    "python3 -m venv Thesis  \n",
    ",in terminal. Afterwards I connected this notebook with the neawly created virual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d1882e",
   "metadata": {},
   "source": [
    "<h3><u>Visual Attention Network</u></h3>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7c4eeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (6.29.5)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (9.1.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: decorator in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.7)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Requirement already satisfied: transformers in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nikolas/venvs/Thesis/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikolas/venvs/Thesis/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nConvNextImageProcessor requires the PIL library but it was not found in your environment. You can install it with pip:\n`pip install pillow`. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load model directly\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoImageProcessor, AutoModelForImageClassification\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m processor = \u001b[43mAutoImageProcessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVisual-Attention-Network/van-base\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m model = AutoModelForImageClassification.from_pretrained(\u001b[33m\"\u001b[39m\u001b[33mVisual-Attention-Network/van-base\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/Thesis/lib/python3.12/site-packages/transformers/models/auto/image_processing_auto.py:559\u001b[39m, in \u001b[36mAutoImageProcessor.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[39m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m image_processor_class.from_dict(config_dict, **kwargs)\n\u001b[32m    558\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m image_processor_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimage_processor_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_dict\u001b[49m(config_dict, **kwargs)\n\u001b[32m    560\u001b[39m \u001b[38;5;66;03m# Last try: we use the IMAGE_PROCESSOR_MAPPING.\u001b[39;00m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m IMAGE_PROCESSOR_MAPPING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/Thesis/lib/python3.12/site-packages/transformers/utils/import_utils.py:1840\u001b[39m, in \u001b[36mDummyObject.__getattribute__\u001b[39m\u001b[34m(cls, key)\u001b[39m\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key.startswith(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key != \u001b[33m\"\u001b[39m\u001b[33m_from_config\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m1840\u001b[39m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/Thesis/lib/python3.12/site-packages/transformers/utils/import_utils.py:1828\u001b[39m, in \u001b[36mrequires_backends\u001b[39m\u001b[34m(obj, backends)\u001b[39m\n\u001b[32m   1826\u001b[39m failed = [msg.format(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[32m   1827\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[32m-> \u001b[39m\u001b[32m1828\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m.join(failed))\n",
      "\u001b[31mImportError\u001b[39m: \nConvNextImageProcessor requires the PIL library but it was not found in your environment. You can install it with pip:\n`pip install pillow`. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "!pip install ipykernel\n",
    "!pip install transformers\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"Visual-Attention-Network/van-base\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"Visual-Attention-Network/van-base\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545e0aa",
   "metadata": {},
   "source": [
    "Run the following if you want the latest version of transformers library. You may encounter isuues.  \n",
    "\n",
    "git clone https://github.com/huggingface/transformers.git  \n",
    "cd transformers  \n",
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29978d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
